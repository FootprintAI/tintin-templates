{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import NamedTuple\n",
    "def trainOp(epochs: int = 50, networks: int = 3) -> NamedTuple('outputs', [('modelfile', str), ('validAcc', float), ('validLoss', float)]):\n",
    "    \n",
    "    import json\n",
    "    import os\n",
    "    import pathlib\n",
    "\n",
    "\n",
    "    home = '/home/jovyan'\n",
    "    \n",
    "   \n",
    "    output_file_dir = os.path.join(home, \"dataprep\")\n",
    "    output_model_dir = os.path.join(home, \"model\") # model dir can't contain anything other than model itself.\n",
    "    output_temp_dir  = os.path.join(home, \".temp\")\n",
    "    model_name = os.environ.get('TINTIN_SESSION_TEMPLATE_MODEL_NAME', 'resnet_graphdef')\n",
    "    model_version = os.environ.get('TINTIN_SESSION_TEMPLATE_MODEL_VERSION', '1')\n",
    "    \n",
    "    \n",
    "    print(\"outputdir:\", output_file_dir)\n",
    "    pathlib.Path(output_file_dir).mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path(output_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path(output_temp_dir).mkdir(parents=True, exist_ok=True)\n",
    "    def load_data():\n",
    "        \n",
    "        import numpy as np\n",
    "        from keras.datasets import cifar10\n",
    "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "        np.save(os.path.join(output_file_dir, 'x_train.npy'), x_train)\n",
    "        np.save(os.path.join(output_file_dir, 'y_train.npy'), y_train)\n",
    "        np.save(os.path.join(output_file_dir, 'x_test.npy'), x_test)\n",
    "        np.save(os.path.join(output_file_dir, 'y_test.npy'), y_test)\n",
    "\n",
    "        \n",
    "    def train(epochs=50, networks=3):\n",
    "        \n",
    "        import os\n",
    "        import shutil\n",
    "        import argparse\n",
    "        import numpy as np\n",
    "\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "        from tensorflow.python.saved_model.signature_def_utils import predict_signature_def\n",
    "        from tensorflow.python.saved_model import tag_constants\n",
    "        from tensorflow.python.saved_model import signature_constants\n",
    "\n",
    "        import keras\n",
    "        from keras.regularizers import l2\n",
    "        from keras import backend as K\n",
    "        from keras.models import Model\n",
    "        from keras import backend as K\n",
    "        from keras.optimizers import Adam\n",
    "        from keras.models import load_model\n",
    "        from keras.layers import Dense, Conv2D\n",
    "        from keras.layers import BatchNormalization, Activation\n",
    "        from keras.layers import AveragePooling2D, Input, Flatten\n",
    "        from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "        from keras.callbacks import ReduceLROnPlateau\n",
    "        #from keras.preprocessing.image import ImageDataGenerator\n",
    "        from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "        import tensorflow.contrib.tensorrt as trt\n",
    "    \n",
    "        validAcc = None\n",
    "        validLoss = None\n",
    "\n",
    "        CONT_TRTIS_RESOURCE_DIR = 'trtis_resource'\n",
    "\n",
    "        # Copy TRTIS resource (containing config.pbtxt, labels.txt, ...) from container to mounted volume\n",
    "        model_dir = os.path.join(output_model_dir, model_name)\n",
    "        if model_version == '1': # if it is default version, we always clear it to keep the space clean\n",
    "            model_verison_dir = os.path.join(output_model_dir, model_name, model_version)\n",
    "            if os.path.isdir(model_verison_dir):\n",
    "                shutil.rmtree(model_verison_dir)\n",
    "        configdotpbtxt = \"\"\"name: \"resnet_graphdef\"\n",
    "platform: \"tensorflow_graphdef\"\n",
    "max_batch_size: 128\n",
    "\n",
    "\n",
    "input [\n",
    "  {\n",
    "    name: \"input_1_1\"\n",
    "    data_type: TYPE_FP32\n",
    "    format: FORMAT_NHWC\n",
    "    dims: [ 32, 32, 3 ]\n",
    "  }\n",
    "]\n",
    "\n",
    "output [\n",
    "  {\n",
    "    name: \"dense_1_1/Softmax\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 10 ]\n",
    "    label_filename: \"labels.txt\"\n",
    "  }\n",
    "]\n",
    "\n",
    "instance_group [\n",
    "  {\n",
    "    count: 2,\n",
    "    kind: KIND_GPU\n",
    "  }\n",
    "]\n",
    "\n",
    "version_policy: { all { }}\n",
    "\"\"\"\n",
    "        labeldottxt = \"\"\"airplane\n",
    "automobile\n",
    "bird\n",
    "cat\n",
    "deer\n",
    "dog\n",
    "frog\n",
    "horse\n",
    "ship\n",
    "truck\"\"\"\n",
    "\n",
    "        \n",
    "        pathlib.Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "        with open(os.path.join(model_dir, 'config.pbtxt'), 'w') as f:\n",
    "            f.write(configdotpbtxt)\n",
    "        with open(os.path.join(model_dir, 'labels.txt'), 'w') as f:\n",
    "            f.write(labeldottxt)\n",
    "\n",
    "        #shutil.copytree(CONT_TRTIS_RESOURCE_DIR, model_dir)\n",
    "        #pathlib.Path(os.path.join(model_dir, model_version)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Training parameters\n",
    "        batch_size = 128  # orig paper trained all networks with batch_size=128\n",
    "        epochs = int(epochs)\n",
    "        data_augmentation = True\n",
    "        num_classes = 10\n",
    "\n",
    "        # Subtracting pixel mean improves accuracy\n",
    "        subtract_pixel_mean = True\n",
    "\n",
    "        n = int(networks)\n",
    "        # Model version\n",
    "        # Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "        version = 2\n",
    "\n",
    "        # Computed depth from supplied model parameter n\n",
    "        if version == 1:\n",
    "            depth = n * 6 + 2\n",
    "        elif version == 2:\n",
    "            depth = n * 9 + 2\n",
    "\n",
    "        # Model name, depth and version\n",
    "        model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "        # Load the CIFAR10 data.\n",
    "        x_train = np.load(os.path.join(output_file_dir, \"x_train.npy\"))\n",
    "        y_train = np.load(os.path.join(output_file_dir, \"y_train.npy\"))\n",
    "        x_test = np.load(os.path.join(output_file_dir, \"x_test.npy\"))\n",
    "        y_test = np.load(os.path.join(output_file_dir, \"y_test.npy\"))\n",
    "\n",
    "        # Input image dimensions.\n",
    "        input_shape = x_train.shape[1:]\n",
    "\n",
    "        # Normalize data.\n",
    "        x_train = x_train.astype('float32') / 255\n",
    "        x_test = x_test.astype('float32') / 255\n",
    "\n",
    "        # If subtract pixel mean is enabled\n",
    "        if subtract_pixel_mean:\n",
    "            x_train_mean = np.mean(x_train, axis=0)\n",
    "            x_train -= x_train_mean\n",
    "            x_test -= x_train_mean\n",
    "\n",
    "        print('x_train shape:', x_train.shape)\n",
    "        print(x_train.shape[0], 'train samples')\n",
    "        print(x_test.shape[0], 'test samples')\n",
    "        print('y_train shape:', y_train.shape)\n",
    "\n",
    "        # Convert class vectors to binary class matrices.\n",
    "        y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "        def lr_schedule(epoch):\n",
    "            \"\"\"Learning Rate Schedule\n",
    "\n",
    "            Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "            Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "            # Arguments\n",
    "                epoch (int): The number of epochs\n",
    "\n",
    "            # Returns\n",
    "                lr (float32): learning rate\n",
    "            \"\"\"\n",
    "            lr = 1e-3\n",
    "            if epoch > 180:\n",
    "                lr *= 0.5e-3\n",
    "            elif epoch > 160:\n",
    "                lr *= 1e-3\n",
    "            elif epoch > 120:\n",
    "                lr *= 1e-2\n",
    "            elif epoch > 80:\n",
    "                lr *= 1e-1\n",
    "            print('Learning rate: ', lr)\n",
    "            return lr\n",
    "\n",
    "        def resnet_layer(inputs,\n",
    "                         num_filters=16,\n",
    "                         kernel_size=3,\n",
    "                         strides=1,\n",
    "                         activation='relu',\n",
    "                         batch_normalization=True,\n",
    "                         conv_first=True):\n",
    "            \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "            # Arguments\n",
    "                inputs (tensor): input tensor from input image or previous layer\n",
    "                num_filters (int): Conv2D number of filters\n",
    "                kernel_size (int): Conv2D square kernel dimensions\n",
    "                strides (int): Conv2D square stride dimensions\n",
    "                activation (string): activation name\n",
    "                batch_normalization (bool): whether to include batch normalization\n",
    "                conv_first (bool): conv-bn-activation (True) or\n",
    "                    bn-activation-conv (False)\n",
    "\n",
    "            # Returns\n",
    "                x (tensor): tensor as input to the next layer\n",
    "            \"\"\"\n",
    "            conv = Conv2D(num_filters,\n",
    "                          kernel_size=kernel_size,\n",
    "                          strides=strides,\n",
    "                          padding='same',\n",
    "                          kernel_initializer='he_normal',\n",
    "                          kernel_regularizer=l2(1e-4))\n",
    "\n",
    "            x = inputs\n",
    "            if conv_first:\n",
    "                x = conv(x)\n",
    "                if batch_normalization:\n",
    "                    x = BatchNormalization()(x)\n",
    "                if activation is not None:\n",
    "                    x = Activation(activation)(x)\n",
    "            else:\n",
    "                if batch_normalization:\n",
    "                    x = BatchNormalization()(x)\n",
    "                if activation is not None:\n",
    "                    x = Activation(activation)(x)\n",
    "                x = conv(x)\n",
    "            return x\n",
    "\n",
    "        def resnet_v1(input_shape, depth, num_classes=10):\n",
    "            \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "            Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "            Last ReLU is after the shortcut connection.\n",
    "            At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "            by a convolutional layer with strides=2, while the number of filters is\n",
    "            doubled. Within each stage, the layers have the same number filters and the\n",
    "            same number of filters.\n",
    "            Features maps sizes:\n",
    "            stage 0: 32x32, 16\n",
    "            stage 1: 16x16, 32\n",
    "            stage 2:  8x8,  64\n",
    "            The Number of parameters is approx the same as Table 6 of [a]:\n",
    "            ResNet20 0.27M\n",
    "            ResNet32 0.46M\n",
    "            ResNet44 0.66M\n",
    "            ResNet56 0.85M\n",
    "            ResNet110 1.7M\n",
    "\n",
    "            # Arguments\n",
    "                input_shape (tensor): shape of input image tensor\n",
    "                depth (int): number of core convolutional layers\n",
    "                num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "            # Returns\n",
    "                model (Model): Keras model instance\n",
    "            \"\"\"\n",
    "            if (depth - 2) % 6 != 0:\n",
    "                raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "            # Start model definition.\n",
    "            num_filters = 16\n",
    "            num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "            inputs = Input(shape=input_shape)\n",
    "            x = resnet_layer(inputs=inputs)\n",
    "            # Instantiate the stack of residual units\n",
    "            for stack in range(3):\n",
    "                for res_block in range(num_res_blocks):\n",
    "                    strides = 1\n",
    "                    if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                        strides = 2  # downsample\n",
    "                    y = resnet_layer(inputs=x,\n",
    "                                     num_filters=num_filters,\n",
    "                                     strides=strides)\n",
    "                    y = resnet_layer(inputs=y,\n",
    "                                     num_filters=num_filters,\n",
    "                                     activation=None)\n",
    "                    if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                        # linear projection residual shortcut connection to match\n",
    "                        # changed dims\n",
    "                        x = resnet_layer(inputs=x,\n",
    "                                         num_filters=num_filters,\n",
    "                                         kernel_size=1,\n",
    "                                         strides=strides,\n",
    "                                         activation=None,\n",
    "                                         batch_normalization=False)\n",
    "                    x = keras.layers.add([x, y])\n",
    "                    x = Activation('relu')(x)\n",
    "                num_filters *= 2\n",
    "\n",
    "            # Add classifier on top.\n",
    "            # v1 does not use BN after last shortcut connection-ReLU\n",
    "            x = AveragePooling2D(pool_size=8)(x)\n",
    "            y = Flatten()(x)\n",
    "            outputs = Dense(num_classes,\n",
    "                            activation='softmax',\n",
    "                            kernel_initializer='he_normal')(y)\n",
    "\n",
    "            # Instantiate model.\n",
    "            model = Model(inputs=inputs, outputs=outputs)\n",
    "            return model\n",
    "\n",
    "        \n",
    "        class LossAndErrorPrintingCallback(keras.callbacks.Callback):\n",
    "            def on_epoch_end(self, epoch, logs=None):\n",
    "                print(\"epoch={}\".format(epoch))\n",
    "                print(\"Training-Accuracy={:7.6f}\".format(logs[\"accuracy\"]))\n",
    "                print(\"Training-Loss={:7.6f}\".format(logs[\"loss\"]))\n",
    "                print(\"Validation-Accuracy={:7.6f}\".format(logs[\"val_accuracy\"]))\n",
    "                print(\"Validation-Loss={:7.6f}\".format(logs[\"val_loss\"]))\n",
    "        \n",
    "        def resnet_v2(input_shape, depth, num_classes=10):\n",
    "            \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "            Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "            bottleneck layer\n",
    "            First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "            Second and onwards shortcut connection is identity.\n",
    "            At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "            by a convolutional layer with strides=2, while the number of filter maps is\n",
    "            doubled. Within each stage, the layers have the same number filters and the\n",
    "            same filter map sizes.\n",
    "            Features maps sizes:\n",
    "            conv1  : 32x32,  16\n",
    "            stage 0: 32x32,  64\n",
    "            stage 1: 16x16, 128\n",
    "            stage 2:  8x8,  256\n",
    "\n",
    "            # Arguments\n",
    "                input_shape (tensor): shape of input image tensor\n",
    "                depth (int): number of core convolutional layers\n",
    "                num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "            # Returns\n",
    "                model (Model): Keras model instance\n",
    "            \"\"\"\n",
    "            if (depth - 2) % 9 != 0:\n",
    "                raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "            # Start model definition.\n",
    "            num_filters_in = 16\n",
    "            num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "            inputs = Input(shape=input_shape)\n",
    "            # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "            x = resnet_layer(inputs=inputs,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=True)\n",
    "\n",
    "            # Instantiate the stack of residual units\n",
    "            for stage in range(3):\n",
    "                for res_block in range(num_res_blocks):\n",
    "                    activation = 'relu'\n",
    "                    batch_normalization = True\n",
    "                    strides = 1\n",
    "                    if stage == 0:\n",
    "                        num_filters_out = num_filters_in * 4\n",
    "                        if res_block == 0:  # first layer and first stage\n",
    "                            activation = None\n",
    "                            batch_normalization = False\n",
    "                    else:\n",
    "                        num_filters_out = num_filters_in * 2\n",
    "                        if res_block == 0:  # first layer but not first stage\n",
    "                            strides = 2    # downsample\n",
    "\n",
    "                    # bottleneck residual unit\n",
    "                    y = resnet_layer(inputs=x,\n",
    "                                     num_filters=num_filters_in,\n",
    "                                     kernel_size=1,\n",
    "                                     strides=strides,\n",
    "                                     activation=activation,\n",
    "                                     batch_normalization=batch_normalization,\n",
    "                                     conv_first=False)\n",
    "                    y = resnet_layer(inputs=y,\n",
    "                                     num_filters=num_filters_in,\n",
    "                                     conv_first=False)\n",
    "                    y = resnet_layer(inputs=y,\n",
    "                                     num_filters=num_filters_out,\n",
    "                                     kernel_size=1,\n",
    "                                     conv_first=False)\n",
    "                    if res_block == 0:\n",
    "                        # linear projection residual shortcut connection to match\n",
    "                        # changed dims\n",
    "                        x = resnet_layer(inputs=x,\n",
    "                                         num_filters=num_filters_out,\n",
    "                                         kernel_size=1,\n",
    "                                         strides=strides,\n",
    "                                         activation=None,\n",
    "                                         batch_normalization=False)\n",
    "                    x = keras.layers.add([x, y])\n",
    "\n",
    "                num_filters_in = num_filters_out\n",
    "\n",
    "            # Add classifier on top.\n",
    "            # v2 has BN-ReLU before Pooling\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = AveragePooling2D(pool_size=8)(x)\n",
    "            y = Flatten()(x)\n",
    "            outputs = Dense(num_classes,\n",
    "                            activation='softmax',\n",
    "                            kernel_initializer='he_normal')(y)\n",
    "\n",
    "            # Instantiate model.\n",
    "            model = Model(inputs=inputs, outputs=outputs)\n",
    "            return model\n",
    "\n",
    "        if version == 2:\n",
    "            model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "        else:\n",
    "            model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=Adam(lr=lr_schedule(0)),\n",
    "                      metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        print(model_type)\n",
    "\n",
    "        # Prepare model model saving directory.\n",
    "        \n",
    "        save_dir = os.path.join(home, 'saved_models')\n",
    "        save_model_name = 'cifar10_%s_model.%03d.h5' % (model_type, epochs)\n",
    "        if not os.path.isdir(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        filepath = os.path.join(save_dir, save_model_name)\n",
    "\n",
    "        # Prepare callbacks for model saving and for learning rate adjustment.\n",
    "        checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                                     monitor='val_accuracy',\n",
    "                                     verbose=1,\n",
    "                                     save_best_only=True)\n",
    "\n",
    "        lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "        lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                                       cooldown=0,\n",
    "                                       patience=5,\n",
    "                                       min_lr=0.5e-6)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        callbacks = [checkpoint, LossAndErrorPrintingCallback(), lr_reducer, lr_scheduler]\n",
    "\n",
    "        # Run training, with or without data augmentation.\n",
    "        if not data_augmentation:\n",
    "            print('Not using data augmentation.')\n",
    "            model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(x_test, y_test),\n",
    "                      shuffle=True,\n",
    "                      callbacks=callbacks)\n",
    "        else:\n",
    "            print('Using real-time data augmentation.')\n",
    "            # This will do preprocessing and realtime data augmentation:\n",
    "            datagen = ImageDataGenerator(\n",
    "                # set input mean to 0 over the dataset\n",
    "                featurewise_center=False,\n",
    "                # set each sample mean to 0\n",
    "                samplewise_center=False,\n",
    "                # divide inputs by std of dataset\n",
    "                featurewise_std_normalization=False,\n",
    "                # divide each input by its std\n",
    "                samplewise_std_normalization=False,\n",
    "                # apply ZCA whitening\n",
    "                zca_whitening=False,\n",
    "                # epsilon for ZCA whitening\n",
    "                zca_epsilon=1e-06,\n",
    "                # randomly rotate images in the range (deg 0 to 180)\n",
    "                rotation_range=0,\n",
    "                # randomly shift images horizontally\n",
    "                width_shift_range=0.1,\n",
    "                # randomly shift images vertically\n",
    "                height_shift_range=0.1,\n",
    "                # set range for random shear\n",
    "                shear_range=0.,\n",
    "                # set range for random zoom\n",
    "                zoom_range=0.,\n",
    "                # set range for random channel shifts\n",
    "                channel_shift_range=0.,\n",
    "                # set mode for filling points outside the input boundaries\n",
    "                fill_mode='nearest',\n",
    "                # value used for fill_mode = \"constant\"\n",
    "                cval=0.,\n",
    "                # randomly flip images\n",
    "                horizontal_flip=True,\n",
    "                # randomly flip images\n",
    "                vertical_flip=False,\n",
    "                # set rescaling factor (applied before any other transformation)\n",
    "                rescale=None,\n",
    "                # set function that will be applied on each input\n",
    "                preprocessing_function=None,\n",
    "                # image data format, either \"channels_first\" or \"channels_last\"\n",
    "                data_format=None,\n",
    "                # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "                validation_split=0.0)\n",
    "\n",
    "            # Compute quantities required for featurewise normalization\n",
    "            # (std, mean, and principal components if ZCA whitening is applied).\n",
    "            datagen.fit(x_train)\n",
    "\n",
    "            # Fit the model on the batches generated by datagen.flow().\n",
    "            model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                steps_per_epoch=len(x_train)/batch_size,\n",
    "                                validation_data=(x_test, y_test),\n",
    "                                epochs=epochs, verbose=1, workers=4,\n",
    "                                callbacks=callbacks)\n",
    "\n",
    "        # Score trained model.\n",
    "        \n",
    "        scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "        \n",
    "        validAcc = scores[1]\n",
    "        validLoss = scores[0]\n",
    "\n",
    "        # Save Keras model\n",
    "        tmp_model_path = os.path.join(output_temp_dir, \"tmp\")\n",
    "        if os.path.isdir(tmp_model_path):\n",
    "            shutil.rmtree(tmp_model_path)\n",
    "        os.mkdir(tmp_model_path)\n",
    "        \n",
    "\n",
    "        keras_model_path = os.path.join(tmp_model_path, 'keras_model.h5')\n",
    "        model.save(keras_model_path)\n",
    "\n",
    "        # Convert Keras model to Tensorflow SavedModel\n",
    "        def export_h5_to_pb(path_to_h5, export_path):\n",
    "            # Set the learning phase to Test since the model is already trained.\n",
    "            K.set_learning_phase(0)\n",
    "            # Load the Keras model\n",
    "            keras_model = load_model(path_to_h5)\n",
    "            # Build the Protocol Buffer SavedModel at 'export_path'\n",
    "            builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "            # Create prediction signature to be used by TensorFlow Serving Predict API\n",
    "            signature = predict_signature_def(inputs={\"input_1\": keras_model.input},\n",
    "                                              outputs={\"dense_1\": keras_model.output})\n",
    "            with K.get_session() as sess:\n",
    "                # Save the meta graph and the variables\n",
    "                builder.add_meta_graph_and_variables(sess=sess, tags=[tag_constants.SERVING],\n",
    "                                                     signature_def_map={signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature})\n",
    "            builder.save()\n",
    "\n",
    "        tf_model_path = os.path.join(output_temp_dir, \"tf_saved_model\")\n",
    "        if os.path.isdir(tf_model_path):\n",
    "            shutil.rmtree(tf_model_path)\n",
    "\n",
    "        export_h5_to_pb(keras_model_path, tf_model_path)\n",
    "\n",
    "        # Apply TF_TRT on the Tensorflow SavedModel\n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():\n",
    "            with tf.Session():\n",
    "                # Create a TensorRT inference graph from a SavedModel:\n",
    "                trt_graph = trt.create_inference_graph(\n",
    "                    input_graph_def=None,\n",
    "                    outputs=None,\n",
    "                    input_saved_model_dir=tf_model_path,\n",
    "                    input_saved_model_tags=[tag_constants.SERVING],\n",
    "                    max_batch_size=batch_size,\n",
    "                    max_workspace_size_bytes=2 << 30,\n",
    "                    precision_mode='fp16')\n",
    "\n",
    "                print([n.name + '=>' + n.op for n in trt_graph.node])\n",
    "                \n",
    "                # note: we should avoid pre-create folder, as inference server will load all models when it started\n",
    "                # and since we created an empty folder, this will crash inference server\n",
    "                pathlib.Path(os.path.join(model_dir, model_version)).mkdir(parents=True, exist_ok=True)\n",
    "                tf.io.write_graph(\n",
    "                    trt_graph,\n",
    "                    os.path.join(model_dir, model_version),\n",
    "                    'model.graphdef',\n",
    "                    as_text=False\n",
    "                )\n",
    "\n",
    "        # Remove tmp dirs\n",
    "        shutil.rmtree(tmp_model_path)\n",
    "        shutil.rmtree(tf_model_path)    \n",
    "        return (validAcc, validLoss)\n",
    "    \n",
    "    load_data();\n",
    "    validAcc, validLoss = train(epochs, networks);\n",
    "    print(\"done\")\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    outputs = namedtuple('outputs', ['modelfile', 'validAcc', 'validLoss'])\n",
    "    return outputs(output_model_dir, validAcc, validLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = trainOp(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    f.write(\"kfp==0.5.1\\n\")\n",
    "    f.write(\"h5py<3.0.0\\n\")\n",
    "    f.write(\"keras==2.3.1\\n\")\n",
    "\n",
    "!pip install -r requirements.txt --user --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.components as comp\n",
    "import kfp.compiler as compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pvcname = os.environ.get('TINTIN_SESSION_TEMPLATE_PVC_NAME')\n",
    "generated_pipeline_zip_filename = os.environ.get('TINTIN_SESSION_TEMPLATE_GENERATED_PIPELINE_ZIP_FILENAME')\n",
    "gpu_type_list_text = os.environ.get('TINTIN_SESSION_TEMPLATE_GPU_TYPE_LIST')\n",
    "default_image = os.environ.get('TINTIN_SESSION_TEMPLATE_DEFAULT_IMAGE', 'footprintai/nvidia-tensorflow:19.12-tf1-py3')\n",
    "mountPath = os.environ.get('TINTIN_SESSION_TEMPLATE_MOUNT_PATH', '/home/jovyan')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainComp = comp.func_to_container_op(trainOp, \n",
    "                                      base_image=default_image,\n",
    "                                      packages_to_install=[\"keras==2.3.1\", \"h5py<3.0.0\"])\n",
    "\n",
    "import kfp.dsl as dsl\n",
    "@dsl.pipeline(\n",
    "   name='Projectname pipeline',\n",
    "   description='simple pipeline.'\n",
    ")\n",
    "def templated_pipeline_func(\n",
    "    epochs=50,\n",
    "    networks=3,\n",
    "):\n",
    "    \n",
    "    pvolumn_dict = {}\n",
    "    pvolumn_dict[mountPath] = dsl.PipelineVolume(pvc=pvcname);\n",
    "    \n",
    "    train_task = trainComp(epochs, networks).add_pvolumes(pvolumn_dict)\n",
    "    train_task = train_task.add_resource_request('cpu', '1')\n",
    "    train_task = train_task.add_resource_limit('cpu', '1')\n",
    "    train_task = train_task.add_resource_request('memory', '4Gi')\n",
    "    train_task = train_task.add_resource_limit('memory', '4Gi')\n",
    "    if len(gpu_type_list_text) > 0:\n",
    "        gpu_type_list = gpu_type_list_text.split(',')\n",
    "        # Set gpu type here. Default the first gpu type in user resource quota.\n",
    "        # User could print out the gpu type list and pick up one to replace the following line.\n",
    "        gpu_type = gpu_type_list[0]\n",
    "        train_task = train_task.add_resource_request(gpu_type, '1')\n",
    "        train_task = train_task.add_resource_limit(gpu_type, '1')\n",
    "        # GPU company is from the GPU type. Used by the gpu driver\n",
    "        gpu_company = gpu_type.split('/')[0] + '/gpu'\n",
    "        train_task = train_task.add_resource_request(gpu_company, '1')\n",
    "        train_task = train_task.add_resource_limit(gpu_company, '1')\n",
    "    model_name = os.environ.get('TINTIN_SESSION_TEMPLATE_MODEL_NAME', 'resnet_graphdef')\n",
    "    train_task = train_task.add_pod_annotation('tintin.footprint-ai.com/session-model-name', model_name)",
    "\n",
    "compiler.Compiler().compile(templated_pipeline_func, generated_pipeline_zip_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

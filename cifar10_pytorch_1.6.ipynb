{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainOp(model_relative_path: str = 'model', model_name: str = 'simple_cifar_pytorch', epochs: int = 50):\n",
    "    ### trainOp served as the main entry point (like main function for most of program languages)\n",
    "    ### it takes several mandatory parameters to configure the path of saved/generated model file\n",
    "    \n",
    "    ### model_relative_path: A persistent volume by default will be mounted at `/home/jovyan` (we called application root here),\n",
    "    ### to keep your state(i.e. files generated) in place.\n",
    "    ### And by default, we want to keep our model generated in `model` relative to application root.\n",
    "    ### However, in background job or hyperparameter tunning, this application root may CHANGED.\n",
    "    ### So in order to perserve model, we use `model_relative_path` to discard variant application root caused.\n",
    "    \n",
    "    ### model_name: a model name will be generated as a file holder (i.e. folder) to all model files generated.\n",
    "    ### In real scenario, the stucture of model file should depends on the inference infrastructure.\n",
    "    ### and in our integration, we requires model should be structured in below:\n",
    "    ### model/\n",
    "    ###        $model_name/\n",
    "    ###                    config.pbtxt\n",
    "    ###                    labels.txt\n",
    "    ###                    $version/\n",
    "    ###                             model.savedmodel/\n",
    "    ###                                              saved_models.pb\n",
    "    \n",
    "    import json\n",
    "    import sys\n",
    "    import os\n",
    "    import pathlib\n",
    "\n",
    "\n",
    "    home = '/home/jovyan'\n",
    "    \n",
    "   \n",
    "    prep_data_dir = os.path.join(home, \"dataprep\")\n",
    "    output_model_dir = os.path.join(home, model_relative_path)\n",
    "    temp_data_dir  = os.path.join(home, \".temp\")\n",
    "    model_version = os.environ.get('TINTIN_SESSION_TEMPLATE_MODEL_VERSION', '1')\n",
    "    \n",
    "    \n",
    "    print(\"outputdir:\", prep_data_dir)\n",
    "    pathlib.Path(prep_data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path(output_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path(temp_data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    # This tranform_data will be used in online serving to tranform data in preprocessing\n",
    "    from tintin.online_serving import save_function_to_model\n",
    "    from tintin.online_serving import transform_data_file_name\n",
    "    @save_function_to_model(model_path=output_model_dir, file_name=transform_data_file_name)\n",
    "    def transform_data(input_data):\n",
    "        input_data = input_data.astype('float32') / 255\n",
    "        input_data -= 0.5\n",
    "        return input_data\n",
    "    \n",
    "    \n",
    "    def load_data():\n",
    "    \n",
    "        import torch\n",
    "        import torchvision\n",
    "        import torchvision.transforms as transforms\n",
    "        \n",
    "        # mimic transform_data defined above but use pytorch\n",
    "        transform = transforms.Compose([transforms.ToTensor(), # from [0,255] -> [0, 1]\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (1, 1, 1))])\n",
    "\n",
    "        batch_size = 64\n",
    "\n",
    "        trainset = torchvision.datasets.CIFAR10(root=prep_data_dir, train=True,\n",
    "                                                download=True, transform=transform)\n",
    "        \n",
    "        # we use testset as validation, so no additional split here\n",
    "        \n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                                  shuffle=True, num_workers=1)\n",
    "        \n",
    "        testset = torchvision.datasets.CIFAR10(root=prep_data_dir, train=False,\n",
    "                                               download=True, transform=transform)\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                                 shuffle=False, num_workers=1)\n",
    "\n",
    "        return (trainloader, testloader)\n",
    "\n",
    "    def export_triton_config_to_modeldir(model_dir:str):\n",
    "        configdotpbtxt = \"\"\"name: \"simple_cifar_pytorch\"\n",
    "platform: \"pytorch_libtorch\"\n",
    "max_batch_size: 128\n",
    "\n",
    "\n",
    "input [\n",
    "  {\n",
    "    name: \"input__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    format: FORMAT_NCHW\n",
    "    dims: [ 3, 32, 32 ]\n",
    "  }\n",
    "]\n",
    "\n",
    "output [\n",
    "  {\n",
    "    name: \"output__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 10 ]\n",
    "    label_filename: \"labels.txt\"\n",
    "  }\n",
    "]\n",
    "\n",
    "version_policy: { all { }}\n",
    "\"\"\"\n",
    "        labeldottxt = \"\"\"airplane\n",
    "automobile\n",
    "bird\n",
    "cat\n",
    "deer\n",
    "dog\n",
    "frog\n",
    "horse\n",
    "ship\n",
    "truck\"\"\"\n",
    "        pathlib.Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "        with open(os.path.join(model_dir, 'config.pbtxt'), 'w') as f:\n",
    "            f.write(configdotpbtxt)\n",
    "        with open(os.path.join(model_dir, 'labels.txt'), 'w') as f:\n",
    "            f.write(labeldottxt)\n",
    "\n",
    "    def train(epochs=50):\n",
    "        \n",
    "        import os\n",
    "        import shutil\n",
    "        import numpy as np\n",
    "        \n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        import torch.nn.functional as F\n",
    "        import torch.optim as optim\n",
    "\n",
    "        (trainloader, testloader) = load_data()\n",
    "\n",
    "        # Copy TRTIS resource (containing config.pbtxt, labels.txt, ...) from container to mounted volume\n",
    "        model_dir = os.path.join(output_model_dir, model_name)\n",
    "        export_triton_config_to_modeldir(model_dir)\n",
    "        \n",
    "        model_verison_dir = os.path.join(output_model_dir, model_name, model_version)\n",
    "        if model_version == '1': # if it is default version, we always clear it to keep the space clean    \n",
    "            if os.path.isdir(model_verison_dir):\n",
    "                shutil.rmtree(model_verison_dir)\n",
    "        pathlib.Path(model_verison_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        class Net(nn.Module):\n",
    "            def __init__(self):\n",
    "                super().__init__()\n",
    "                self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "                self.pool = nn.MaxPool2d(2, 2)\n",
    "                self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "                self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "                self.fc2 = nn.Linear(120, 84)\n",
    "                self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.pool(F.relu(self.conv1(x)))\n",
    "                x = self.pool(F.relu(self.conv2(x)))\n",
    "                x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "                x = F.relu(self.fc1(x))\n",
    "                x = F.relu(self.fc2(x))\n",
    "                x = self.fc3(x)\n",
    "                return x\n",
    "\n",
    "        net = Net()\n",
    "        if torch.cuda.is_available():\n",
    "            net = net.cuda()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "        \n",
    "        for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "            train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            for inputs, labels in trainloader:\n",
    "                # Transfer Data to GPU if available\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                preds = net(inputs)\n",
    "                loss = criterion(preds, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss = loss.item() * inputs.size(0)\n",
    "                _, pred_labels = torch.max(preds, dim = 1)\n",
    "                train_correct += (pred_labels == labels).float().sum()\n",
    "            \n",
    "            valid_loss = 0.0\n",
    "            valid_correct = 0\n",
    "            for inputs, labels in testloader:\n",
    "                # Transfer Data to GPU if available\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                # Forward Pass\n",
    "                preds = net(inputs)\n",
    "                # Find the Loss\n",
    "                loss = criterion(preds,labels)\n",
    "                # Calculate Loss\n",
    "                valid_loss = loss.item() * inputs.size(0)\n",
    "                _, pred_labels = torch.max(preds, dim = 1)\n",
    "                valid_correct += (pred_labels == labels).float().sum()\n",
    "\n",
    "            # print stats for each epoch\n",
    "            print(\"epoch={}\".format(epoch))\n",
    "            print(\"Training-Accuracy={:7.6f}\".format(train_correct / len(trainloader)))\n",
    "            print(\"Training-Loss={:7.6f}\".format(train_loss / len(trainloader)))\n",
    "            print(\"Validation-Accuracy={:7.6f}\".format(valid_correct / len(testloader)))\n",
    "            print(\"Validation-Loss={:7.6f}\".format(valid_loss / len(testloader)))\n",
    "        \n",
    "        # convert pytorch model to typescript model\n",
    "        sample = torch.rand(64, 3, 32, 32)\n",
    "        if torch.cuda.is_available():\n",
    "            sample = sample.cuda()\n",
    "        scripted_model = torch.jit.trace(net, sample)\n",
    "        torch_model_path  = os.path.join(model_dir, model_version, 'model.pt')\n",
    "        scripted_model.save(torch_model_path)\n",
    "\n",
    "    train(epochs)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### if you want to debug the above tranOp function,\n",
    "### uncomment below\n",
    "### and remember to COMMENT it before you `BUILD` this pipeline through UI\n",
    "\n",
    "# trainOp('model', 'resnet_graphdef', 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    f.write(\"kfp==0.5.1\\n\")\n",
    "    f.write(\"h5py<3.0.0\\n\")\n",
    "    f.write(\"tintin-sdk>=0.0.4\\n\")\n",
    "    f.write(\"ipywidgets==7.6.3\\n\")\n",
    "    f.write(\"torch==1.6.0\\n\")\n",
    "    f.write(\"torchvision==0.7.0\\n\")\n",
    "    f.write(\"tqdm >=4.62.1\\n\")\n",
    "\n",
    "!pip install -r requirements.txt --user --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.components as comp\n",
    "import kfp.compiler as compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pvcname = os.environ.get('TINTIN_SESSION_TEMPLATE_PVC_NAME')\n",
    "generated_pipeline_zip_filename = os.environ.get('TINTIN_SESSION_TEMPLATE_GENERATED_PIPELINE_ZIP_FILENAME')\n",
    "gpu_type_list_text = os.environ.get('TINTIN_SESSION_TEMPLATE_GPU_TYPE_LIST')\n",
    "default_image = os.environ.get('TINTIN_SESSION_TEMPLATE_DEFAULT_IMAGE', 'footprintai/nvidia-tensorflow:19.12-tf1-py3')\n",
    "mountPath = os.environ.get('TINTIN_SESSION_TEMPLATE_MOUNT_PATH', '/home/jovyan')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainComp = comp.func_to_container_op(trainOp, \n",
    "                                      base_image=default_image,\n",
    "                                      packages_to_install=[\"h5py<3.0.0\", \"tintin-sdk>=0.0.4\", \"ipywidgets==7.6.3\", \"torch==1.6.0\", \"torchvision==0.7.0\", \"tqdm >=4.62.1\"])\n",
    "\n",
    "import kfp.dsl as dsl\n",
    "@dsl.pipeline(\n",
    "   name='Projectname pipeline',\n",
    "   description='simple pipeline.'\n",
    ")\n",
    "def templated_pipeline_func(\n",
    "    epochs=50,\n",
    "):\n",
    "    \n",
    "    ### model relative path can NOT be nest path(e.g. a/b/c/d, it should be the first folder (e.g. model)\n",
    "    model_relative_path = os.environ.get('TINTIN_SESSION_TEMPLATE_MODEL_RELATIVE_PATH', 'model')    \n",
    "    model_name = os.environ.get('TINTIN_SESSION_TEMPLATE_MODEL_NAME', 'simple_cifar_pytorch')\n",
    "    ### if you want to customize $model_name, replace `my_customized_model_name` and uncomment below\n",
    "    ### model_name = os.environ.get('TINTIN_SESSION_TEMPLATE_MODEL_NAME', 'my_customized_model_name')\n",
    "    \n",
    "    train_task = trainComp(model_relative_path, model_name, epochs)\n",
    "    # add train_task default resources for cpu and memory, this value will be changed during runtime\n",
    "    # to reflect your settings in UI\n",
    "    train_task = train_task.add_resource_request('cpu', '1')\n",
    "    train_task = train_task.add_resource_limit('cpu', '1')\n",
    "    train_task = train_task.add_resource_request('memory', '4Gi')\n",
    "    train_task = train_task.add_resource_limit('memory', '4Gi')\n",
    "    \n",
    "    # add annotation to reflect our configuration on `model_relative_path` and `model_name` to workflow itself.\n",
    "    train_task = train_task.add_pod_annotation('tintin.footprint-ai.com/session-model-relative-path', model_relative_path)    \n",
    "    train_task = train_task.add_pod_annotation('tintin.footprint-ai.com/session-model-name', model_name)\n",
    "compiler.Compiler().compile(templated_pipeline_func, generated_pipeline_zip_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

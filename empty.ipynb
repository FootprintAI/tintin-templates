{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trainOp(model_relative_path: str = 'model', model_name: str = 'resnet_graphdef'):\n",
    "    ### trainOp served as the main entry point (like main function for most of program languages)\n",
    "    ### it takes several mandatory parameters to configure the path of saved/generated model file\n",
    "    \n",
    "    ### model_relative_path: A persistent volume by default will be mounted at `/home/jovyan` (we called application root here),\n",
    "    ### to keep your state(i.e. files generated) in place.\n",
    "    ### And by default, we want to keep our model generated in `model` relative to application root.\n",
    "    ### However, in background job or hyperparameter tunning, this application root may CHANGED.\n",
    "    ### So in order to perserve model, we use `model_relative_path` to discard variant application root caused.\n",
    "    \n",
    "    ### model_name: a model name will be generated as a file holder (i.e. folder) to all model files generated.\n",
    "    ### In real scenario, the stucture of model file should depends on the inference infrastructure.\n",
    "    ### and in our integration, we requires model should be structured in below:\n",
    "    ### model/\n",
    "    ###        $model_name/\n",
    "    ###                    config.pbtxt\n",
    "    ###                    labels.txt\n",
    "    ###                    $version/\n",
    "    ###                             model.savedmodel/\n",
    "    ###                                              saved_models.pb\n",
    "    import pathlib\n",
    "    import os\n",
    "    \n",
    "    home = '/home/jovyan'\n",
    "    output_model_dir = os.path.join(home, model_relative_path)\n",
    "    model_dir = os.path.join(output_model_dir, model_name)\n",
    "    \n",
    "    # create an empty model dir\n",
    "    pathlib.Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    ## begin your code here\n",
    "    ## ....\n",
    "    ## end your code here\n",
    "    \n",
    "    \n",
    "    ## use monitorCallback to let tintin to track your model performance, hence a comparison view can be used\n",
    "    #class LossAndErrorPrintingCallback(keras.callbacks.Callback):\n",
    "    #        def on_epoch_end(self, epoch, logs=None):\n",
    "    #            print(\"Training-Accuracy={:7.6f}\".format(logs[\"accuracy\"]))\n",
    "    #            print(\"Training-Loss={:7.6f}\".format(logs[\"loss\"]))\n",
    "    #            print(\"Validation-Accuracy={:7.6f}\".format(logs[\"val_accuracy\"]))\n",
    "    #            print(\"Validation-Loss={:7.6f}\".format(logs[\"val_loss\"]))\n",
    "    #callbacks = [..., LossAndErrorPrintingCallback(), ...]\n",
    "    #    # Run training, with or without data augmentation.\n",
    "    #    if not data_augmentation:\n",
    "    #        print('Not using data augmentation.')\n",
    "    #        model.fit(x_train, y_train,\n",
    "    #                  batch_size=batch_size,\n",
    "    #                  epochs=epochs,\n",
    "    #                  validation_data=(x_test, y_test),\n",
    "    #                  shuffle=True,\n",
    "    #                  callbacks=callbacks)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### if you want to debug the above tranOp function,\n",
    "### uncomment below\n",
    "### and remember to COMMENT it before you `BUILD` this pipeline through UI\n",
    "\n",
    "# = trainOp('model', 'resnet_graphdef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to access assets files, use tintin-sdk (requires python >=3.7)\n",
    "### see tintin-sdk: https://github.com/footprintAI/tintin-sdk\n",
    "#!pip install tintin-sdk --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write all your requirements.txt here if possible\n",
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    f.write(\"kfp==1.4.0\\n\")\n",
    "    f.write(\"h5py<3.0.0\\n\")\n",
    "    f.write(\"tintin-sdk\\n\")\n",
    "\n",
    "!pip install -r requirements.txt --user --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.components as comp\n",
    "import kfp.compiler as compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pvcname = os.environ.get('TINTIN_SESSION_TEMPLATE_PVC_NAME')\n",
    "generated_pipeline_zip_filename = os.environ.get('TINTIN_SESSION_TEMPLATE_GENERATED_PIPELINE_ZIP_FILENAME')\n",
    "gpu_type_list_text = os.environ.get('TINTIN_SESSION_TEMPLATE_GPU_TYPE_LIST')\n",
    "default_image = os.environ.get('TINTIN_SESSION_TEMPLATE_DEFAULT_IMAGE', 'footprintai/nvidia-tensorflow:19.12-tf1-py3')\n",
    "mountPath = os.environ.get('TINTIN_SESSION_TEMPLATE_MOUNT_PATH', '/home/jovyan')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainComp = comp.func_to_container_op(trainOp, \n",
    "                                      base_image=default_image)\n",
    "\n",
    "import kfp.dsl as dsl\n",
    "@dsl.pipeline(\n",
    "   name='Projectname pipeline',\n",
    "   description='simple pipeline.'\n",
    ")\n",
    "def templated_pipeline_func(\n",
    "):\n",
    "    \n",
    "    ### model relative path can NOT be nest path(e.g. a/b/c/d, it should be the first folder (e.g. model)\n",
    "    model_relative_path = os.environ.get('TINTIN_SESSION_TEMPLATE_MODEL_RELATIVE_PATH', 'model')    \n",
    "    model_name = os.environ.get('TINTIN_SESSION_TEMPLATE_MODEL_NAME', 'resnet_graphdef')\n",
    "    ### if you want to customize $model_name, replace `my_customized_model_name` and uncomment below\n",
    "    ### model_name = os.environ.get('TINTIN_SESSION_TEMPLATE_MODEL_NAME', 'my_customized_model_name')\n",
    "    \n",
    "    train_task = trainComp(model_relative_path, model_name)\n",
    "    # add train_task default resources for cpu and memory, this value will be changed during runtime\n",
    "    # to reflect your settings in UI\n",
    "    train_task = train_task.add_resource_request('cpu', '1')\n",
    "    train_task = train_task.add_resource_limit('cpu', '1')\n",
    "    train_task = train_task.add_resource_request('memory', '4Gi')\n",
    "    train_task = train_task.add_resource_limit('memory', '4Gi')\n",
    "    \n",
    "    # add annotation to reflect our configuration on `model_relative_path` and `model_name` to workflow itself.\n",
    "    train_task = train_task.add_pod_annotation('tintin.footprint-ai.com/session-model-relative-path', model_relative_path)    \n",
    "    train_task = train_task.add_pod_annotation('tintin.footprint-ai.com/session-model-name', model_name)\n",
    "compiler.Compiler().compile(templated_pipeline_func, generated_pipeline_zip_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
